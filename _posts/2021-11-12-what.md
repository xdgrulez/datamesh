---
title: The what
author: Pavan Keshavamurthy
date: 2021-01-12
category: Introduction
layout: post
toc: true 
---

# Data Mesh: The Case for "What"

2021 is the year that the data mesh trend hit the high point of it's hype cycle. Unsurprisingly, there is a lot of marketing buzz around the theme that makes it difficult to specify in plain old technical terms, a descriptive vision of what a data mesh in practice might look like. To this end, we attempt to partially build on top of Zhamak et al, but may diverge in some ways from their vision. We're cognizant that this definition may evolve in the face of emerging trends, but we will attempt to disambiguate what a data mesh is, from a standpoint of what it _should technically do_, based on adjacent metaphors & first principles.

Let us first investigate then very notion of the "mesh" in the data mesh. In Wikipedia's definition,

> Network topology is the topological structure of a network and may be depicted physically or logically. It is an application of graph theory wherein communicating devices are modeled as nodes and the connections between the devices are modeled as links or lines between the nodes. Physical topology is the placement of the various components of a network (e.g., device location and cable installation), while logical topology illustrates how data flows within a network. Distances between nodes, physical interconnections, transmission rates, or signal types may differ between two different networks, yet their logical topologies may be identical.

Simply put, the data mesh is a network of data; a digitally mature adaptation of the same networking metaphor, but wherein the communication devices (ie, the nodes)  are substituted by data producing or consuming entities, and the edges represent some process (movement, transformation) that acts upon the data in transit. The data mesh manifests in a foundational sense, as the _fabric_ in which these interactions occur, across an organization's business domain or the organization itself. 

The primary heuristic for the data mesh lies in it's _coverage_ (span) of data lifecycle and  _connectedness_ of interactions across the organization; The typical data organization of today, quite in contrast, is a wild-west of disconnected data producers & consumers. Central IT, App, Product team silos form ravines in which hypercentralized data engineering teams extract data from the modern oil rig (metaphorically), pump it large distances to storage lakes & warehouses where it is confined to further fossilization, albeit for the occasionally adventurous intervention of advanced analtics & machine learning teams which may from time to time perform groundbreaking discoveries.

The mesh model also asserts a subtle emphasis on low latency & brokered relay of data streams across the data network with fan out effects. This is in stark contrast to layered data architectures, which are strongly bounded, point to point connectivity, often with batch centric, push-pull data movement semantics 

Finally, We should also suggest that data mesh is best thought of as a _modern_ operating model for enterprise-wide data. As is the case with any operating model, or transition from one to another, the data mesh brings in aspects that touches upon People, Process & Tooling. There maybe aspects of this operating model that will map to products or platform capabilities and will closely align to cloud-native principles. 

To this end, we posit that Domain Oriented data ownership, productization, self service platform and governance are organic downstream consequences of adopting a data mesh operating model.
An A16Z Future publication on "Emerging Architectures for Modern Data Infrastructure" specifically calls out on the great convergence of AI/ML and Analytics. They narrow in on 3 data architecture blueprints, based on organizational goals; namely (1) Modern BI (2) Multi-modal data processing (3) AI and ML. We feel, architecturally, the data mesh is a best fit for customer use-cases fitting archetype (2) - Multi-modal data processing, usually with an affinity towards use-cases involving a multitude of data sources, complex transformation processes, combined with traditional and advanced analytics.

{{{ insert: a16z data architecture blueprints; annotate the overarching coverage of the data mesh }}}

# Import concepts & abstractions


{{{ insert: illustration of the data mesh components & abstracions }}}

In attempting to define what a data mesh would look like, it is important to establish a few conventions & architectural abstractions based on separations of concerns. We borrow inspiration generously from networking & general distributed systems terminology that is adjacent to this problem space.

- Data Services

Data services is an abstraction for the primary constituent units of the mesh. A data service is broadly anything that interacts with the mesh, and is typically a data producing application ("publisher") or a data consuming application ("consume"); Data services operate upon an atomic unit of data, understand how data must be serialized, deserialized, marshalled and have ordering awareness. Within this spectrum, there maybe a variety of data integration concerns that they perform, which can involve complex data manipulation or transformation. Data services form the nodes of topologies and sub-topologies of the prospective mesh. 

- Data Brokers

Data brokers are abstractions that disintermediate data producers & consumers. They move data between and across a distributed mesh, whilst providing ordering & delivery guarentees, along with quality of service. 

- Mesh Data Plane

The mesh data plane is the configurable, distributed topology in which data flow & interactions between the services & the brokers occurs.

- Mesh Control Plane

The mesh control provides the policy oriented, declarative control & command the behaviour of the data plane.


# Opportunities in the mesh: Cross cutting concerns


{{{ illustration: opportunities - in the mesh }}}

The all encompassing coverage of a network has some interesting side-effects, which provide both upstream & downstream opportunities, a capability leveraged by network infrastructure widely and in recent times adopted at the same buzzword scale by service meshes. The most important amongst them is providing to cover common, cross-cutting IT concerns.


We explore them briefly below and shall cover them in depth in the following chapters.

- Discovery

Discovery means, dynamically finding new services that onboard into the mesh; It also means providing routing capabilities to downstreams so that they can insulate from actual physical addressing of the services & resources and letting the mesh hanlde it for them. 

- Observability

Observability means the ability to determine a system's internal state. Data processing or movement across the mesh involves several hops. The nature of the mesh provides for the ability to trace down to a single atomic unit of data and it's journey across the mesh. Another consequence of this observability to to construct the data's pedigree, also known as lineage; An associated idea is that of understanding the data's provenance (or "where it really came from"); 

- Security

The stakes around security are high. Data out of the network is fundamentally data out of control. Therefore, caution and governance must be utilized on who can access what data at any point in time; This is broadly, authentication and authorization. Data sovereignity and data principal level controls (for consent, forgettability) are overarching regulatory subjects. Security in the mesh is the broad coverage of security concerns, involving management of authentication and authorization, encryption at rest/transit and deidentification of data flowing across.

- Quality of Service

Quality of service is the ability to provide optimal performance of the mesh in itself, aligned to the use-cases of the data mesh clients. This includes managing & enforcing quotas, load-balancing & distrubition of traffic, enforcing retry budgets & failover to ensure avvailablity and performance.


# Downstream opportunities

We have so far discussed discussed the mesh in itself. Standardizing on a mesh interface, can alos commoditize several functions that can be fulfilled by best in breed tooloing. A non exhaustive list of possibilities:  

- Event & Data Sourcing

The Digital enterprise is a factory of applications (best thought of as products that map to business value); Products are composed of services that model the domain and capture a rich graph of business events & interactions. Event sourcing & domain driven aggregates are the very foundation for building modern software architectures. The interactions encapsulated in these services involve events and data, which are two sides of the same coin. In reality, application factories require invasive intevention & modernization to adopt this model. Databases (with CDC) and APIs provide the next best line of eventing sources that can feed into a mesh, although they are comparatively anemic in contrast to ground-up event driven architectures. 

The data mesh has great scope in generic integrations that can glue well with:

-- Integration Systems (API Gateways, Middleware, Service Meshes)
-- Databases
-- Applications (directly)


- Data Processing

Data processing involves topology to fit flow requirements. In practice, this can manifest as carefully designed flow (orchestration) or loosely controlled coordination (choreography) to process & move data. A mesh can provide for both, thus enabling new possibilities in the data processing & integration models that are necessary in the enterprise.

- Data Governance

Data Governance is the process of (ideally, out of band) policy based management, measurement & controls of the data lifecycle. The data mesh presents a multitude of use-cases in governance, including but not restricted to metadata management, quality and overall data lifecycle insights. 

# Technology freedom & pluggable data/control plane components

- The Data Plane:
- The Control Plane: 
